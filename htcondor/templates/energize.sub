universe = vanilla
+WantFlocking = true
+WantGlideIn = false

log = output/condor_logs/rosetta_$(Cluster)_$(Process).log
error = output/condor_logs/rosetta_$(Cluster)_$(Process).err
output = output/condor_logs/rosetta_$(Cluster)_$(Process).out

# rosetta provides the precompiled 64bit binaries for linux
# has_avx is included because I think I ran into avx-related errors in the past
# todo: update these requirements if any jobs fail, etc
requirements = (Arch == "X86_64") && (has_avx == true) && (OpSys=="LINUX")

executable = run.sh

should_transfer_files = YES
when_to_transfer_output = ON_EXIT

# todo: update input files to whatever the new system will be
transfer_input_files = run.sh, args.tar.gz, energize_args.txt
transfer_output_files = output

request_cpus = 1
request_memory = 2GB
request_disk = 10GB

# for github authentication, token=$ENV(token) will take the environment variable $token from the submit node
# and pass it forward to each job server. to avoid storing the token on the submit node, can try to pass it in
# on each call to condor_submit by setting the environment variable just for that call
# https://stackoverflow.com/questions/10856129/setting-an-environment-variable-before-a-command-in-bash-is-not-working-for-the
environment = "CLUSTER=$(Cluster) PROCESS=$(Process) runningon=$$(Name) GITHUB_TAG=$ENV(GITHUB_TAG) TOKEN=$ENV(TOKEN)"

queue $ENV(NUM_JOBS)
