{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e05adf28",
   "metadata": {},
   "source": [
    "# Parse KosciolekAndJones raw PDBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1d3b35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# reload modules before executing code in order to make development and debugging easier\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa945938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this jupyter notebook is running inside of the \"notebooks\" directory\n",
    "# for relative paths to work properly, we need to set the current working directory to the root of the project\n",
    "# for imports to work properly, we need to add the code folder to the system path\n",
    "import os\n",
    "from os.path import abspath, join, isdir, basename, isfile\n",
    "import sys\n",
    "if not isdir(\"notebooks\"):\n",
    "    # if there's a \"notebooks\" directory in the cwd, we've already set the cwd so no need to do it again\n",
    "    os.chdir(\"..\")\n",
    "module_path = abspath(\"code\")\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6f1879d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import itertools \n",
    "import shutil\n",
    "import textwrap\n",
    "\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqIO.PdbIO import AtomIterator\n",
    "from Bio.PDB import PDBParser\n",
    "from Bio.PDB.Polypeptide import PPBuilder\n",
    "from Bio.Seq import Seq \n",
    "from Bio.SeqUtils import seq1\n",
    "from Bio import pairwise2\n",
    "from Bio.pairwise2 import format_alignment \n",
    "from biopandas.pdb import PandasPdb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9654c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14299159",
   "metadata": {},
   "source": [
    "# Grab the raw PDBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef2332c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_dir = \"pdb_files/KosciolekAndJones/pdbs_raw\"\n",
    "pdb_fns = [join(pdb_dir, x) for x in os.listdir(pdb_dir) if x.endswith(\".pdb\")]\n",
    "pdb_ids = [basename(x)[:-4] for x in pdb_fns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ce00f1",
   "metadata": {},
   "source": [
    "# Identify missing residues with the SEQRES method\n",
    "For each PDB file, read the sequence from (1) SEQRES records and (2) ATOM records. If sequences match, they *should be* good to go (no missing residues). However, some of them might have **modified** residues. Biopython parses modified residues as regular residues, so it's impossible to tell which residues are modified based on the sequence returned by Biopython. In the PDB file, the modified residues show up as modified in the MODRES, SEQRES, and ATOM records. The modified residues are usually listed as HETATM instead of ATOM.\n",
    "\n",
    "Another way to check for missing residues could be to look at the residue numbers and make sure they are sequential without any gaps. However, this fails if the missing residues are at the start or end of the sequence. So prefer the SEQRES method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7366423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of sequences from SEQRES\n",
    "seqres_seqs = []\n",
    "for pdb_fn in pdb_fns:\n",
    "    found_chain_A = False\n",
    "    for record in SeqIO.parse(pdb_fn, \"pdb-seqres\"):\n",
    "        if record.annotations[\"chain\"] == \"A\":\n",
    "            found_chain_A = True\n",
    "            seqres_seqs.append(str(record.seq))\n",
    "    if not found_chain_A:\n",
    "        print(\"no chain A for {}\".format(basename(pdb_fn)))\n",
    "\n",
    "# list of sequences from ATOM records\n",
    "atom_seqs = []\n",
    "with warnings.catch_warnings(record=True):\n",
    "    # suppress biopython warnings because the atom records are missing residues\n",
    "    for pdb_fn in pdb_fns:\n",
    "        found_chain_A = False\n",
    "        for record in SeqIO.parse(pdb_fn, \"pdb-atom\"):\n",
    "            if record.annotations[\"chain\"] == \"A\":\n",
    "                found_chain_A = True\n",
    "                atom_seqs.append(str(record.seq))\n",
    "        if not found_chain_A:\n",
    "            print(\"no chain A for {}\".format(basename(pdb_fn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e70fc595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the PDBs where the seqres seqs and the atom seqs are equivalent\n",
    "# these *should be* ready-to-go because all residues that should be present \n",
    "# according to seqres are in fact present in the atoms\n",
    "equiv = []\n",
    "non_equiv = []\n",
    "for pdb_fn, seqres_seq, atom_seq in zip(pdb_fns, seqres_seqs, atom_seqs):\n",
    "    if seqres_seq == atom_seq:\n",
    "        equiv.append(pdb_fn)\n",
    "    else:\n",
    "        non_equiv.append(pdb_fn)\n",
    "\n",
    "missing_residues = [basename(x)[:-4] for x in non_equiv]\n",
    "not_missing_residues = [basename(x)[:-4] for x in equiv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b41e9dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not missing residues: 50\n",
      "Missing residues: 100\n"
     ]
    }
   ],
   "source": [
    "print(\"Not missing residues: {}\".format(len(not_missing_residues)))\n",
    "print(\"Missing residues: {}\".format(len(missing_residues)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27ed09d",
   "metadata": {},
   "source": [
    "## Not actually missing residues\n",
    "\n",
    "Note! There are some PDBs that were identified as having missing residues in the above section, but they don't actually have missing residues. Instead, they have extra residues being read in from the ATOM seqs due to weirdness with the ATOM seqs. These PDBs are '1bsg', '1dix', '1i4j', '1ek0', '5ptp'. They get processed successfully with Rosetta's clean_pdb.py, so we can just use the raw PDBs for them (or the chain A-only \"clean\" PDBs). \n",
    "\n",
    "This was discovered after ready_set_1.txt was created (below), so they are going to be processed with the second round of PDBs (along with ones that got remodeled due to having missing residues)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f20d3600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seqres == atom: True\n",
      "seqres len: 131, atom len: 131\n",
      "seqres seq:\n",
      "QADGAKIYAQCAGCHQQNGQGIPGAFPPLAGHVAEILAKEGGREYLILVLLYGLQGQIEVKGMKYNGVMS\n",
      "SFAQLKDEEIAAVLNHIATAWGDAKKVKGFKPFTAEEVKKLRAKKLTPQQVLAERKKLGLK\n",
      "atom seq:\n",
      "QADGAKIYAQCAGCHQQNGQGIPGAFPPLAGHVAEILAKEGGREYLILVLLYGLQGQIEVKGMKYNGVMS\n",
      "SFAQLKDEEIAAVLNHIATAWGDAKKVKGFKPFTAEEVKKLRAKKLTPQQVLAERKKLGLK\n"
     ]
    }
   ],
   "source": [
    "idx = pdb_ids.index(\"1c52\")\n",
    "print(\"seqres == atom:\", seqres_seqs[idx] == atom_seqs[idx])\n",
    "print(\"seqres len: {}, atom len: {}\".format(len(seqres_seqs[idx]), len(atom_seqs[idx])))\n",
    "print(\"seqres seq:\")\n",
    "print(\"\\n\".join(textwrap.wrap(seqres_seqs[idx])))\n",
    "print(\"atom seq:\")\n",
    "print(\"\\n\".join(textwrap.wrap(atom_seqs[idx])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bd3851",
   "metadata": {},
   "source": [
    "## Actually missing residues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff8df2a",
   "metadata": {},
   "source": [
    "There are 2 PDB files that are actually missing residues: 1c52 and 1fx2. They have residues with zero occupancy that are removed by clean_pdb.py."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61312ca",
   "metadata": {},
   "source": [
    "# Identify modified residues with MODRES records\n",
    "PandasPDB makes it easy to parse other records, such as MODRES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39368e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppdbs = [PandasPdb().read_pdb(pdb_fn) for pdb_fn in pdb_fns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59f58500",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_residues = []\n",
    "for pdb_id, ppdb in zip(pdb_ids, ppdbs):\n",
    "    others = ppdb.df[\"OTHERS\"]\n",
    "    if \"MODRES\" in others.record_name.unique():\n",
    "        # modified residue only a concern if it's a different amino acid code\n",
    "        # i think glycosylation site and disulfide bridge aren't a problem\n",
    "        # but just in case, should check with Phil\n",
    "        mr = others[others.record_name == \"MODRES\"]\n",
    "        concerning_modres = mr[\"entry\"].apply(lambda x: x[6:9] != x[18:21]).any()\n",
    "        if concerning_modres:\n",
    "            modified_residues.append(pdb_id)\n",
    "#         print(pdb_id)\n",
    "#         print(others[others.record_name == \"MODRES\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e51140be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified residues: 21\n"
     ]
    }
   ],
   "source": [
    "print(\"Modified residues: {}\".format(len(modified_residues)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac12515",
   "metadata": {},
   "source": [
    "# Figure out which PDBs are ready to go\n",
    "And which need more work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d01fd493",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_only = set(missing_residues) - set(modified_residues)\n",
    "missing_and_modified = set(missing_residues).intersection(set(modified_residues))\n",
    "modified_only = set(modified_residues) - set(missing_residues)\n",
    "ready_set_1 = set(not_missing_residues) - set(modified_residues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "195e0277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDBs with only missing residues, no modified residues (83)\n",
      "1cxy 1jkx 2tps 1chd 1guu 1dmg 1d1q 1nrv 1g2r 1cc8 1hxn 1fl0 1vmb 1a3a 1fqt 1xdz 1jo0 1mug 1dqg 3dqg 1hh8 1bkr 1hdo 2arc 1kqr 1roa 1k6k 1bsg 1xff 1ihz 1kid 1lo7 1aap 1tzv 1dix 3bor 1m8a 1jvw 1xkr 1im5 1d4o 1qjp 1beh 1tqh 1ctf 1ryb 1ku3 1eaz 1r26 1jfu 1vjk 1m4j 1smx 1atl 1o1z 1i1n 1jl1 1i4j 1fvk 1wjx 1d0q 1iib 1jos 1vp6 1avs 2vxn 1hfc 1atz 1jbk 2cua 1vfy 1ktg 1rw7 1gmi 1tif 1cke 1beb 1p90 1jyh 1j3a 1i1j 1h98 1f6b\n"
     ]
    }
   ],
   "source": [
    "print(\"PDBs with only missing residues, no modified residues ({})\\n{}\".format(len(missing_only), \" \".join(missing_only)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2390df9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDBs with missing residues and modified residues (17)\n",
      "1svy 1fvg 1kq6 1pko 1ek0 1ne2 1h4x 1lm4 1w0h 1gz2 1wkc 1kw4 1vhu 1dbx 1ny1 1lpy 5ptp\n"
     ]
    }
   ],
   "source": [
    "print(\"PDBs with missing residues and modified residues ({})\\n{}\".format(len(missing_and_modified), \" \".join(missing_and_modified)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "951c65dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDBs with no missing residues, only modified residues (4)\n",
      "1rw1 1gmx 1jbe 1k7j\n"
     ]
    }
   ],
   "source": [
    "print(\"PDBs with no missing residues, only modified residues ({})\\n{}\".format(len(modified_only), \" \".join(modified_only)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a12c402d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDBs with no missing residues and no modified residues (46)\n",
      "1a70 1pch 1c9o 1gbs 1k7c 1a6m 1dsx 1ej8 1ej0 1ql0 1cjw 1jwq 1dlw 1c52 1g9o 1i5g 1brf 1jo8 1h2e 1fna 1tqg 1gzc 1fk5 2mhr 1c44 1whi 1i58 1t8k 1aoe 1aba 2hs1 1i71 1fx2 1bdo 1iwd 1jfx 1nb9 1ag6 1nps 1h0p 1mk0 2phy 1czn 1qf9 1fcy 1htw\n"
     ]
    }
   ],
   "source": [
    "print(\"PDBs with no missing residues and no modified residues ({})\\n{}\".format(len(ready_set_1), \" \".join(ready_set_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548f2615",
   "metadata": {},
   "source": [
    "# Create list of ready-to-go PDBs (ready_set_1)\n",
    "This is ready_set_1.txt. PDB files from the list of 150 that are ready for the prepare pipeline without having to deal with missing or modified residues. \n",
    "\n",
    "Note this list is missing some PDBs that were originally thought to have missing residues, but do not (see section 3.1). Additionally, some PDBs with modified residues are also ready-to-go in that Rosetta's clean_pdb will fill in modified residues with canonical amino acids. However, these PDBs with modified residues were not included in this list.\n",
    "\n",
    "Note this list includes 2 PDBs that have residues with zero occupancy and are thus filtered out with clean_pdb.py (leaving missing residues). These were remodeled and need to be re-run through energize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "56f303c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pdb_files/KosciolekAndJones/ready_set_1.txt\", \"w\") as f:\n",
    "    for pdb_id in sorted(ready_set_1):\n",
    "        f.write(f\"pdb_files/KosciolekAndJones/pdbs_chains/{pdb_id}_A.pdb\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d81e9c",
   "metadata": {},
   "source": [
    "## Copy prepared PDB files from ready_set_1 to main prepared directory\n",
    "In between this step and previous step, the pdb files from ready_set_1.txt were run through the prepare pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "95e40026",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pdb_files/KosciolekAndJones/ready_set_1.txt\", \"r\") as f:\n",
    "    rs1_pdb_ids = [basename(x.strip())[:-4] for x in f.readlines()]\n",
    "\n",
    "# copy from prepare_outputs directory to prepared_pdb_files\n",
    "prep_outputs_dir = \"output/prepare_outputs\"\n",
    "outputs_mapping = {}\n",
    "for d in os.listdir(prep_outputs_dir):\n",
    "    outputs_mapping[d[:6]] = join(prep_outputs_dir, d, \"{}_p.pdb\".format(d[:6]))\n",
    "\n",
    "final_output_dir = \"pdb_files/prepared_pdb_files\"\n",
    "for pdb_id in rs1_pdb_ids:\n",
    "    shutil.copy(outputs_mapping[pdb_id], final_output_dir)\n",
    "#     print(outputs_mapping[pdb_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe618ecc",
   "metadata": {},
   "source": [
    "# Create list of ready-to-go PDBs (ready_set_2)\n",
    "\n",
    "This is ready_set_2.txt. PDB files that have modified residues that are still able to be processed by clean_pdb and have the modified residues replaced with canonical residues. Also PDB files that were thought to have missing residues, but actually don't. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "474c46ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ready_set_2 = [\"1rw1\", \"1gmx\", \"1k7j\", \"1bsg\", \"1dix\", \"1i4j\", \"1ek0\", \"5ptp\"]\n",
    "with open(\"pdb_files/KosciolekAndJones/ready_set_2.txt\", \"w\") as f:\n",
    "    for pdb_id in sorted(ready_set_2):\n",
    "        # note we are processing them from the RAW pdb's instead of pdbs_chains this time. \n",
    "        # clean_pdb will take care of selecting chain A (as long as we specify it when we call the prepare pipeline)\n",
    "        # this is taken care of in prepare_2.sh\n",
    "        # could probably just ues pdbs_chains like last time, but I tested it pdbs_raw, so keep it that way for now\n",
    "        f.write(f\"pdb_files/KosciolekAndJones/pdbs_raw/{pdb_id}.pdb\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4131085e",
   "metadata": {},
   "source": [
    "## Copy prepared PDB files from ready_set_2 to main prepared directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "27d805a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5283b1",
   "metadata": {},
   "source": [
    "# Create list of ready-to-go PDBs (ready_set_3) \n",
    "These are from loop modeling. Note, I originally filtered out 1c52 and 1fx2 but these actually DO need to be taken from remodel rather than raw. So, I manually ran them through prepare afterward, but then updated this code to not filter them out, so in case this needs to be run in the future, it can just be run from here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f90d5af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "checks_fn = \"pdb_files/KosciolekAndJones/loop_modeling/data/remodel_checks.csv\"\n",
    "checks = pd.read_csv(checks_fn)\n",
    "checks.columns = [\"code\", \"passed\"]\n",
    "checks[\"passed\"] = checks[\"passed\"].apply(lambda x: True if x.strip() == \"True\" else False)\n",
    "\n",
    "ready_set_3 = set(checks[checks[\"passed\"]][\"code\"])\n",
    "# note there are 2 PDBs that were remodeled but don't appear to be missing any residues (1c52 and 1fx2)\n",
    "# make sure to remove these from ready_set_3 as we don't need to re-run them\n",
    "# to accomplish this we just remove ready_set_1 and ready_set_2 to be sure we aren't running duplicates\n",
    "# EDIT: Nevermind, these DO need to be included.\n",
    "# ready_set_3 = ready_set_3 - ready_set_1 - set(ready_set_2)\n",
    "\n",
    "with open(\"pdb_files/KosciolekAndJones/ready_set_3.txt\", \"w\") as f:\n",
    "    for pdb_id in sorted(ready_set_3):\n",
    "        # note these are coming from the pdbs_remodel directory (from root KosciolekAndJones folder, not loop_modeling)\n",
    "        # these PDB files are the same as the ones from the loop modeling but have been renamed _remod\n",
    "        f.write(f\"pdb_files/KosciolekAndJones/pdbs_remodel/{pdb_id}_remod.pdb\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e36dfb",
   "metadata": {},
   "source": [
    "## Copy prepared PDB files from ready_set_3 to main prepared directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2580f66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c934536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a197777",
   "metadata": {},
   "source": [
    "# Examine outputs from loop modeling (testing stuff out)\n",
    "PDBs that were not \"ready to go\" were run through the loop modeling protocol to fill in missing residues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f14fd6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "checks_fn = \"pdb_files/KosciolekAndJones/loop_modeling/data/remodel_checks.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5a899725",
   "metadata": {},
   "outputs": [],
   "source": [
    "checks = pd.read_csv(checks_fn)\n",
    "checks.columns = [\"code\", \"passed\"]\n",
    "checks[\"passed\"] = checks[\"passed\"].apply(lambda x: True if x.strip() == \"True\" else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f9cfe9",
   "metadata": {},
   "source": [
    "PDBs that were remodeled but don't have missing residues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "fe720281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1c52', '1fx2'}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(checks[checks[\"passed\"]][\"code\"]) - missing_only - missing_and_modified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acf4c17",
   "metadata": {},
   "source": [
    "PDBs that have missing residues but weren't remodeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c66ef4b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1bsg', '1dix', '1i4j'}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_only - set(checks[\"code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "adf13e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1ek0', '5ptp'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_and_modified - set(checks[\"code\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8d1032",
   "metadata": {},
   "source": [
    "PDBs that were unsuccessfully remodeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ac7b7edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>passed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1a3a</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1aap</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1atl</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1atz</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1avs</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2cua</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2tps</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2vxn</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>3bor</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3dqg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    code  passed\n",
       "0   1a3a    True\n",
       "1   1aap    True\n",
       "2   1atl    True\n",
       "3   1atz    True\n",
       "4   1avs    True\n",
       "..   ...     ...\n",
       "93  2cua    True\n",
       "94  2tps    True\n",
       "95  2vxn    True\n",
       "96  3bor    True\n",
       "97  3dqg    True\n",
       "\n",
       "[92 rows x 2 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checks[checks[\"passed\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d8fba9d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1gz2', '1hdo', '1i1n', '1j3a', '1jbe', '1lm4'}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pdbs that will be covered between ready_set_1 and all the ones that passed the remodel\n",
    "manual_process = [\"1rw1\", \"1gmx\", \"1k7j\", \"1bsg\", \"1dix\", \"1i4j\", \"1ek0\", \"5ptp\"]\n",
    "set(pdb_ids) - set(checks[checks[\"passed\"]][\"code\"]) - ready_set_1 - set(manual_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591063ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
